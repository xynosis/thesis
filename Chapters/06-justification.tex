\chapter{A grounded theory of justification, classification and performance practices}
\label{6}

\section{Introduction}
\label{sec:6-intro}

% i think i could make a compelling connection between this kind of infrastructural ethnography and service design 

The changes brought about by austerity have led to affects and experiences marked by powerlessness, distrust, isolation, confusion and anxiety. Yet to begin to construct methods moving beyond these affects and experiences and to disrupt capitalist realism, it is important to understand how austerity-intensified capitalist realism took hold in the care system in the first place, and how it maintains its hegemony. Broadly, the roots of these changes can be located within the changes made to youth service funding in 2011 (referenced in \ref{2}) - particularly, the new importance given to evaluation within the ‘value for money’ agenda. In this chapter, I construct a grounded theory to describe the three sets of changes in practice to The Charity I have witnessed - focused in turn on justification, classification, and performativity. These practices support each other in turn. Justification practices refer to the new justificatory labour that workers within The Charity have to undertake, constantly contorting their actually-existing practice with young people to justify their work to funding organisations and other bodies. Classification practices refer to the regime that upholds these justifications, a tightly bounded classification system, where funders, policy organisations and thinktanks engage in attempts to delimit and classify the kinds of work (or the kinds of people) that organisations should be engaging in/with, which encourages the biopolitical techniques of control explored in the previous chapter. Finally, the looping effects of these justification and classification practices generate a performativity that saturates contemporary culture - and which creates new economies predicated upon vulnerability.

I end the chapter by discussing what the existence of a performative knowledge ecosystem such as this, with tightly bounded classifications and justification practices might mean for the care system and those attempting to engage in liberatory practice within it. I outline how young people, workers, managers and organisations suffer as a result of this and highlight other contexts in which justification practices likely exist. Moreover, I detail the technological and policy implications of this system, which rewards certain kinds of knowledge production over others, regardless of the fidelity of the data which goes into this. I identify how this poses significant issues for contemporary sociotechnical challenges such as dealing with mis/disinformation (‘fake news’), and the creation of artificial intelligence (AI), machine-learning (ML), or automated decision-making  (ADM) social welfare systems, particularly regarding issues of trust. 

\subsection{The rise of evaluation in practice}
As mentioned in \ref{2}, the House of Commons Education Committee's report on youth service provision led to a slew of changes to how youth services were operated, funded, and evaluated. Although evaluation has always had a role to play within youth and social work a central feature of social and youth service since [year], the 2011 report acted as a point of intensification, with a call for a "common evaluation framework" (ref, find wording). This common evaluation framework came in the form of the government's Framework for Young People's Outcomes (2012), developed by the Catalyst Consortium (The Young Foundation, National Council for Voluntary Youth Services, the National Youth Agency and Social Enterprise UK). The Framework articulated a clear idea for how organisations should conceptualise their work: in terms of extrinsic and intrinsic, and individual and social outcomes.

The framework also outlined several tools and technologies which were already being used by organisations who delivered youth services. We find many tools and technologies mentioned and language used in the report in frequent use in contemporary youth and social work: outcomes, activities and outputs; the use of Triangles Consultings' 'Outcomes Star' for evaluating an individual's change in outcomes over time; use of the database technology VIEWS to manage individual outcomes; the use of theories of change and logic models to explain intended impact; references to baselines, benchmarks, indicators and monitoring; and discussions of resilience, risky behaviours and protective factors. The Framework for Young People's Outcomes partly set the standard for youth services measurement and evaluation, but it also reflected the practice of the time. It is important to stress that the justification practices I am about to explore are not necessarily new: they are the latest form of forces that have existed for much longer, and are clearer to see because of their current prevalence. The Framework amplified what was already there. 

The Framework drew upon a recent history of evidence-based policy-making. As Edwards et al. (2016: 1-2) highlight, the turn towards evidence-based policymaking 'appears to be indisputably desirable and unquestionable commonsense'. Yet this indisputability is a function of capitalist realism itself, and, as Edwards et al. note, this assumption is rooted in a 'modernising, new manageralist approach to governance in which social values and moral issues are reduced to technical rationality'. The turn to evidence-based policymaking saw a movement towards early years intervention in youth and social work, out of a belief that these are critical moments for a child's development. Whilst this is true, it is not the \emph{only} critical developmental period. As Edwards et al. highlight, 'neuroscientific evidence... is not necessarily called upon its for its actual explanatory capacity, but for its persuasive value' (6). In a later article, the same researchers suggest that the alliance between the social and the life sciences here is dangerous, because of the way that biological explanations are employed without any of the assumptions inherent within them being explored or explicated. This obscures any other possible explanation. These same processes play out through justification practices in the context of austerity, with persuasion - or justification - being the central currency, rather than explanation itself. 

Following the Framework, services were required to conceptualise their work in terms of outcomes and outputs and use tools such as those provided in the Framework to create a case as to why (and sometimes how) their practice works. If they didn't, they risked punitive measures from funders, or the possibility of not receiving funding at all. [Mari] (the director of Small Steps) told me that this was incredibly different to how things used to be. [Mari] described the early 2000s (when Small Steps got started) as a time of "magic and luck, but also definitely waste". She and a few others had an idea for a new project so they went to their local authority with that idea alone: a youth work service specifically for care-experienced young people. At the time, care-experienced young people were being turned away from 'universal services' because of the perception that they had additional needs. The authority agreed to fund her if she could provide an itemised budget for the program, she did so, and the project was funded. In retrospect, she told me that she had realised that the itemised budget hadn't equalled the total: she had budgeted for £13,000 but the items only totalled £11,000. Perhaps this is an example of the 'huge waste' that [Mari] described that was part of this time of 'magic and luck'. Yet without this 'waste', Small Steps might not exist today. Under the deeply structured evaluation and justification regime that is in place now, it is impossible to imagine a project being funded with even £10 unaccounted for, let alone £2,000.

Other workers spoke about this process - the introduction of austerity and the changes in youth service funding - in a similarly evocative way. A worker who I met when she was leading training around young people's rights and entitlements explained to me:

It feels like it's all about the money now. The government's really limited with what they fund now... and the whole system is like a pressure cooker about to explode. It's only a matter of time.

Similarly, a man who worked for a regional mental health charity who I met opportunistically told me that:

The public sector had its heart ripped out, and in its place... it's all budget driven now.

These two views eloquently describe the scene presented in the previous chapter. Managers, workers and young people are isolated, disconnected, disempowered and stuck in ever-more-precarious situations. What better way to understand this than to think of it as simultaneously having its heart ripped out and being about to explode? The care system plods on, zombie-like and lifeless, fulfilling the tasks it needs to,  going through the motions to tick its boxes and move young people around placements. All the while it's doing this, it's oblivious to the fires starting inside of it; the constantly-building-pressure, the explosion that is just waiting to happen. Simultaneously, then, the care system is zombie and explosion: nothing meaningful is happening, but it looks like it is working; yet on closer inspection, it is full of little fires everywhere, only just-about-contained.


------
change above slightly as well to be less poetic 

perhaps skip the perfromance practicess and use that as the discussion - what results is performativity 

Let us look, then, at that container, the zombielike body that makes it appear that things are carrying on as normal. This is, of course, evaluation processes. As I will detail shortly, evaluation has taken the central role in the management of youth and social work, as all other activities - even the delivery of actual youth and social work - become secondary to 'a good evaluation'. Without good evaluation, organisations risk losing their funding, and being unable to do any good. So it makes sense to put time, money and energy into getting evaluation right. Right? For the sake of clarity: no. I argue that evaluation processes in their current form are responsible for a great deal of bad practice circulating in the care system, and, more than this, are circulating for bad knowledge about good practice circulating in the care system. If we pursue a funding-led, evidence-based policy agenda, we are inevitably led to a place where getting funded matters more than doing good things.

I refer to the changes in practices and behaviour that led to the creation of the experiences and affective states described in the previous chapter as 'justification practices'. They are termed as such because they describe the first (and primary) function that I saw them performing: to justify, to explain why, to defend. Charities are forced to justify their programs of activity to their funders and over bodies which have oversight of their work. Because they exist in a scarcity environment (Brown, XXXX), they are more inclined to lie about their work than to explain what they are doing authentically - even if what they are doing is good!

I will furnish you with a brief example before turning to the specific dynamics of justification practices. When Jake became manager of the youth work team within Small Steps (promoted from her previous position as Senior Youth Worker), one of her first tasks was completing a report back to a funder on a recent piece of work that the team had delivered. This was her first time writing such a report, and she set about it with gusto, explaining the great work the team had done, detailing some of the impacts they had made, the number of sessions delivered, where they were delivered, and so on. She sent the report to the funder. They replied quickly: "you delivered your activities in a different place than you said you were going to in your proposal. Why have you done this?" Jake had already explained this in her report - upon receiving the funding, Small Steps had realised that there were no suitable venues available when the project was supposed to run in the town they had listed in their funding document. The team set about finding a new venue, and found one in the next town over. This made no difference to the activities: Small Steps provides transport for young people to attend their activities, as they operate in a rural area, so it just meant telling drivers to go to one place instead of the other. This wasn't good enough for the funder. In their eyes, they had funded them to deliver activities in that town only, because they perceived it to be an area of great need. Changing the town basically changed the project. Small Steps was in discussions with the funder for another six months, back and forth on this one tiny change. When [Mari] learned what Jake had done (in telling the truth in the evaluation report), she simply said: "that's not how we do things. But at least you've learned now."

\section{The components of justification practices}
We know what results from justification practices: as detailed in chapter 4, they bring about XXXX. What makes them happen, though? How are they sustained? What is the everyday experience of being inside-of-justification-practices, and how do they develop?
It is important to remember that the creation and maintenance of regimes of evaluation and justificaiton are not the core work of charities providing support services to young people percevied to be vulnerable. This comes as an additional burden on top of their daily practice, often added on as a piece of everyone's responsibility, which no-one really likes. A staff member of Small Steps made clear it wasn't necessarily that it was that this was a great deal of labour:

It's not even so much work, per se... it's so much evidence.

The labour of evidencing the ways in which someone has changed that can be attributed to the intervention of one specific project is significant and highly specialist, and there is little consideration of this in people's workloads.

What does evaluation actually consist of? At a rudimentary level, most evaluation in the youth support service sphere revolves around the delivery of outputs, and the observation of changes in outcomes. Outputs tend to refer to the activity of a project - what is being delivered, to how many people, for how long, and the material artefacts that can prove the existence of these outputs. For example, for a mental health project, you might deliver an hour-long session weekly over three months, and at the end of it have made a film documenting individuals' progress throughout the three months. These could be considered outputs. At the beginning of those three months, you might ask your participants a series of questions about how they are feeling about themselves, their life, and the situations they are in. This is your baseline. Throughout the project, you might repeatedly ask your participants these same questions - perhaps with the help of the Outcomes Star - and by the end of the project, you will have a clear picture of how your participants' understanding of themselves, their life and the situations they are in have changed. These are their outcomes, and what your funder really cares about is what changes in outcomes your project can deliver for as little money as possible. In short, how you can deliver 'value for money' (probs ref). Outputs and outcomes are mutually enmeshed: outputs can become evidence in an evaluation process, and a change in outcomes can become an output of its own accord.

Before outcomes can be identified, however, evaluation methods which must be chosen and deployed to decide the remit of the project. These will determine how a project is framed (to funders, policymakers and participants), and the circumstances of its success. This might result in the use of some other tools from the Framework for Young Peoples' Outcomes - for example, you might decide to make a theory of change or logic model which describes the impact your project intends to make (or, at a higher level, you might do this for your entire team or organisation). Then you will ensure your activities or outputs link up to the impact that you intend to make. Does that homelessness reduction project really make sense for your educational technology charity? You've not identified homelessness as a priority area in your theory of change. Sometimes - perhaps too often - this happens the other way around, a project has already been delivered and the team that delivered it is trying to justify why what they did matters and how it constitutes 'value for money'. This retrospective evaluation approach can mean that it is less important to follow a theory of change than to be able to retrofit your already-delivered project into a theory of change and evaluation scheme. Creating a theory of change retrospecitively is a great deal easier than doing so beforehand: simply look at the change you have made, wrap an explanation around it, and hey presto, you are capable of delivering a project which makes all of the change you intended to make. This is, of course, because you didn't intend to make any change in the first place.

\subsection{Outputs and outcomes}
Let's look in closer detail at outputs and outcomes, and how work practices have changed to accommodate the need to capture these.

\subsubsection{Outcomes}
When a project is established, it is working for the improvement of certain ‘outcomes’. As explained in the Framework for Young People's Outcomes, these outcomes can be considered to be 'hard' or 'soft' - "tangible 'results' such as educational achievement, participation in training, exclusion from school, offending or challenging behaviour" or "social and emotional capabilities", which are deemed harder to assess. In short, hard outcomes have some level of binary - they are happening or they aren't happening - and soft outcomes are deeply subjective. Since the advent of austerity, multiple workers explained that "soft outcomes counted less’", though a few workers felt that things were getting a little better in recent years. If a project's funding does allow for softer outcomes, though, then there is a need to determine how these outcomes are measured. Soft outcomes require a rudimentary understanding of research practice - how do we measure? What do we measure? How often do we measure? How can we develop a proxy measure for emotional self-management, for example?

There is an acknowledgement amongst workers that though these measures are needed to assess the (relative) success of a project, they are "deeply, deeply flawed". This type of measurement work doesn't feel natural to many care workers, such as [Claire], who in my time working with her wanted to "find a fun way to assess" different outcomes. It didn't feel right to her to stick a survey on the end of a project, so it felt important to her that she develop a method of measuring that suited her youth work practice. This is not always possible, of course. Particularly in situations of greater trauma, risk or perceived vulnerability, there may not be "a fun way" to evaluate something: sometimes you just need to understand the extent to which a young person understands the abusive situation they recently found themselves in.

Because the evaluation process is directly linked to an organisation being able to demonstrate that they provide 'value for money', outcomes and their measurement become significant elements of the conduct of any given project. Multiple times throughout my engagements with Small Steps and Building Bridges, for example, I witnessed workers being told to "nail down what their outcomes are" or to "familiarise [themselves] with the outcomes". This speaks to the indeterminacy of measuring outcomes - the project happens regardless, and it must be decided which outcomes are measured. This can often be an act of convenience: what has been the clearest change? What do we know how to evidence? For these workers, evaluation work is hard and requires a great deal of focused attention. Workers who spent more time working closely with evaluation schemes, though, were able to "put [their] outcomes head on" as Jake often did, conjuring appropriate outcomes for a given project out of thin air. The measurement of outcomes becomes a discrete practice which has little connection to frontline youth and social work.

Some workers struggle to adopt this practice or to see how it is something they should be doing. They see their work as the delivery and planning of youth and social work. For them, the measurement of outcomes is (rightfully) secondary to the delivery of meaningful care for young people. Yet this means that when they are forced to engage in evaluation processes or outcomes measurement, there can be a great deal of confusion about outcomes. Karen repeatedly struggled to tell the difference between "what an outcome is, [and] what an output is" as when she joined her role at Building Bridges it wasn't a natural part of her practice. Elsewhere, I witnessed this same confusion result in managers having to constantly clarify certain terms and how and when to apply them, in order to help their workers "make the link [from their practice] to what is measured" with varying degrees of success.

\subsubsection{Outputs}
Outputs are the traces a project leaves in the world; it is what the project does, and what is left once the project is over. In their traditional sense, outputs mostly relate to the act of delivering the project, but because of the importance of capturing information for evaluation, things which might have normally been considered are beginning to be used in evaluation processes of their own accord. Outputs can be referred to in impact and evaluation reports and future funding proposals. As such, the traces of one project can help to give birth to a new project if used in the right way. We can think of this process almost as alchemy: some changes are applied to matter (a program is delivered), traces are kept of those changes (outputs), and by applying a XXX process to these traces we can create a new project (get our new project funded). As such, there has been a move towards visual or otherwise performative outputs, which are most easily used in funding proposals or evaluation reports because of their self-evident or easily explainable nature.

Centrally, these visual outputs tend towards the use of photography and film to document work as it is happening. Facilitated by the prevalence of camera-enabled smartphones, every worker with a smartphone is now able to collect evidence for evaluation purposes. [Sharon] (Changemakers) would frequently tell Kolinn and [Arron] to take photos and videos whenever they went out to work with young people or visit other organizations, to create documentation of what they were doing and spending funding on. Regardless of any negative social consequences, from the perspective of data security and privacy, this was hugely problematic as the organization did not provide work phones for their staff. As such, all photos and videos of young people that were taken were stored on workers' personal phones, embedded into whatever ecosystem they personally used to store photos (such as iCloud, Google Photos, Dropbox Photos etc.). These breaches of personal privacy and data protection happened constantly; it was more important to [Sharon] that she was able to document the organization's work and promote a positive image of the organization than to engage in the sort of meaningful participatory work that the charity claimed to deliver.

This was not an isolated incident though; it happens at every scale, in multiple organizations. On the second weekend residential of Building Bridges, at [Richard]'s request, I spent the weekend filming the activities to demonstrate to the organizations’ trustees what their money was being spent on. After the weekend, he uploaded these videos to an open Google Drive folder to share with the trustees. Soon after, it became clear that these videos had been shared with one of the young peoples’ care service - technically a breach of GDPR (as the video had not been recorded for these purposes) and certainly a breach of the young peoples’ privacy. The turn towards these documentation practices undermines the autonomy and agency that these organizations are trying to build with young people, in favour of performing a positive image of their work. More on uses of film?

The cultivation of a positive image is key to how outputs participate in justification practices. Visual outputs are favoured because they are subjective, and can be easily embedded in any narrative the organisation wishes to cultivate. Images and videos can be decontextualised and re-deployed in another context: consider how often the smiling faces of young people participating in residentials are used to advertise the work of a charity. Yet their enjoyment is never solely because of the charity, and to pretend as such again strips them of the autonomy and agency these organizations are trying to build. This performativity - and the pressure to be performative - is amplified by social media websites and the identities that charities have to cultivate through these. In many instances, I have witnessed organisations share photos on social media without the young people they have taken photos of providing any consent. Maybe slightly more. I detail more on the intersection of justification practices and social media in the following chapter.

Securing accreditation plays a unique role for projects led by these charities. These might include things such as the Arts Award, the National Citizenship Service, any one of the courses offered by AQA's 'unit awards', the Duke of Edinburgh award or the Sports Leader award. These accreditations are often thought about as bringing benefits to the young people who achieve them - a clear sign that they have been working towards something important and valuable. Young people are often sold on the idea that this will help them to secure employment, because it will look good on a job application. Yet in reality, these accreditation schemes are of greater benefit to the organisations who facilitate them. The number of young people who have achieved various kinds of accreditaiton through their work with the charity becomes an easy shorthand for the charity to explain their impact - "we have had 6 young people complete their gold Duke of Edinburgh this year, 30 young people achieve their bronze Arts Award", and so on. This can lead to the integration of accreditation schemes just for the sake of them. During my fieldwork, [Kate] at Small Steps was assigned the task of finding out about some changes to some accreditaiton schemes that were upcoming and feed back to the rest of the group. She proudly reported back that what she had found out, "basically, is that you can fit accreditation into anything". I witnessed this first hand with Building Bridges - even at the point where we constructing the project, and it was absent of content and just an outline of a scheme, we were having conversations about what kind of accreditation we should put into it. We could try Arts Award, because its criteria was so open. Maybe something more significant would be better. Or maybe it would put young people off. When Small Steps were in the very first meeting about a potential idea for a new project, Jake interjected:

The other thing - sorry guys - Bronze arts award? It sounds like a perfect fit!

Once Small Steps and the collaborating organization had established that yes, the Bronze Arts Award might be a great fit - then came the discussion of who it would count for:

I don't see any reason why it can't count for both of us. That'll tick some boxes for us if we do.

Within this, there was no consideration of whether the Bronze Arts Award was something that young people who might participate wanted to do, and to spend time evidencing and complete. Instead it was just tacked onto the scheme, a clear output for everyone involved.
In its worst case, this output-led culture can affect the core of the organization itself. When Changemakers were struggling to attract funding, they decided to embark upon a "rebrand". They felt that was probably the reason that they weren't receiving funding, and that the "look and feel" of the organization must be outdated because other organizations' branding and visual design was much sleeker and "young person friendly". They rebranded the entire organization, working with a design agency to rethink everything. No stone was left unturned - they ran workshops with young people with experience of homelessness to determine which colours they preferred, which logos they liked, and even considered renaming the charity at one point. The redesign process took months, and when everything was in place, nothing changed. There was no difference in engagement from either young people or funders after the redesign. Moving towards visual and performative outputs in this encourages charities to undertake work which has no substantive relationship to their aims, and instead prioritizes work that looks like a lot but has little material impact.

In all of these cases, what was most important was that the organization appeared to be doing well, to be looking good, that things seemed okay. Photos and videos make it look like you're doing something. Having a social media presence helps build an impression you're constantly working with young people. Securing accreditation gives you externally verifiable ways to refer to the impacts you make. Redesigning your organization through a 'participatory' desifgn process makes it seem as if your very identity is driven by the young people you work with. Despite all of the appearance of 'impact' here though, these practices tend to divert from the organisation's core purpose and the cause of making material change for young people perceived to be vulnerable. They add an additional data collection step to all frontline youth and social work practice, and although ostensibly this may be for the purposes of reflexive practice or some similarly named endeavour, it is infrequent that there is the level of skill or spare capacity within the organization that is needed to manage changes made as a result of internal reflexivity. What remains then is a certain level of performativity: organizations spend more time and energy ensuring that they are appearing to make change than actually attempting to make change.

\subsection{How evaluation work gets done}
We might think of outcomes and outputs as a kind of currency; accrue enough and link them together in the right way and you can trade them in for some funding for your organization. Yet if outcomes and outputs are currency, we need to ask two questions: how do we earn this currency, and how do we spend it? What goes into the actual production of outcomes and outputs, and what work practices are engendered to stabilise this? How do organizations go through a process of transforming material reality into outcomes and outputs, then evaluation reports, and then further funding?

Before I dive into a description of the experiences underpinning this work, I will detail how it functions at the theoretical level. Here, I borrow extensively from Woolgar and Latour. In Laboratory Life (197X), Woolgar and Latour describe the ways in which material reality (in the form of scientific experiments) become transformed into academic research papers and thus greater esteem for the authors and organization. First, some empirical state is observed. An inscription is then made of this with an inscription device. This may be as simple as a measurement noted on a piece of paper, or can be as technical as a [specific thing about technology from book]. Then, through [explanation], this becomes transformed into a different inscription [explanation]. In much the same way, evaluation of charity work has become a series of inscriptions and transformations. [maybe more detail on issue sof measurement and quantification].

Broadly, we can speak of two versions of this transformation process: a skilled transformation and an unskilled transformation. We might think of the skilled transformation as being conducted by an expert magician, a Flamel-like alchemist, who excels at the transubstantiation of matter into something completely new. We might think of our unskilled transformation as being conducted by your mate who does card tricks at weddings. They get the job done, and you suppose it's magic, but it only really fools your drunk Uncle Billy. The unskilled transformation is the sort of evaluation that is conducted by organisations with limited capacity, knowledge of evaluation, or lack of funding. Generally, this means smaller local or regional charities. The skilled transformation is conducted by large organisations, national charities, local authorities, thinktanks and government bodies. These sorts of transformation use the size and capital-power of the organisation to hire highly skilled evaluation professionals and utilise their expertise to their advantage. In both cases, the data underpinning the evaluation tends to be highly contingent and subjectively deployed, but they pose distinct problems to the functioning of the care system.

\subsubsection{Unskilled evaluation}
As mentioned, unskilled evaluation tends to take place in organisations which either lack capacity, knowledge of good evaluation practices, or which lack stable or plentiful funding. Because of this lack of expertise, the process of creating data on young people's outcomes are highly contingent and subjective. These workers are often overworked and will likely have received little training in evaluation, research or data management. Additionally, their workloads tend not to take account of the high volume of data-creation they must engage in, and so it tends to become a low priority task, done only when it has to be. Data is created with little consideration to how it might be used, with workers only ensuring they are playing "the numbers game" - getting enough participants for a project to hit its outcomes. In one instance, a pair of workers were evaluating a young person’s behaviour over the course of a weekend residential. One worker implored the other to not give the young person "top whack… yet":

KA: “She’s definitely a 4. Don’t put her as a 5.”

K: “I don’t know, I think she’s a 5.”

KA: “No, she’s a 4. She’s fat, but she knows she’s fat. So she’s a 4. You’re too nice.”

In the process of conducting evaluations for young people, workers are thinking more about how they can demonstrate a young person’s progress over the course of a project than actually evaluating the work that is happening. [Kate] was new to her role, though she had been a trained youth worker for years she was returning to practice after several years of being a teacher. On a scale of 5, [Kerry-Ann], more experienced with how things worked, wanted to ensure there was room for improvement - because then Small Steps could take credit for that improvement. It is also clear just how subjective this is - how well a young person appears to do is at the whim of two workers deciding on a number. Magnify that process by several thousand, and you have data-creation and evaluation processes in organisations which have to engage in unskilled evaluation.

The unskilled nature of this kind of evaluation can also result in completely unsuitable forms of measurement or evaluation. In Kolinn's previous job, for example, he worked with with young people who were perceived to be at risk of grooming or sexual exploitation. They would work with young people over a period of some weeks, and they would complete an Outcomes Star after each session. One of the outcomes was centered on how likely they thought they were to be at risk of sexual exploitation. Over the course of the program, young people would tend to 'improve' in this outcome, that is, by the end they would think there more at risk than when they started. Of course, this was the intention of the intervention - to inform young people of the risks that they might encounter and give them a toolkit to deal with these. Yet a cursory view at this data might instead suggest that engaging in the program makes young people more likely to be sexually exploited, which is not the intention. Kolinn told me of a few occassions when senior management, not understanding the intricacies of the project, had demanded explanations for these poor outcomes - and every time, staff would have to explain that what was happening was, essentially, intended.

All of this is not to say that the practice of the workers is wrong. They are doing the best with what they have. Nonetheless, it results in a poor-quality dataset that appears to be of a high quality. I will return to the specifics of how this problem manifests shortly, but for now I will just highlight that this is a significant issue in a culture which focuses on evidence-based policymaking and the creation of automated decision-making systems based on data from these services. If the data these rest upon are so subjectively created, what is their use?

\subsubsection{Skilled evaluation}
Skilled evaluation is undertaken by organisations that can pay for the skill. Mostly, this tends towards national charities, government bodies, and thinktanks. These organisations pay teams of people whose entire job is evaluation. This is the opposite of unskilled organisations; there, it is everyone's job to do a little evaluation - here, it is a few people's job to do all of the evaluation. One advantage of practitioner-led evaluation, despite its flaws, is that there is always a clear link to frontline practice. The person evaluating tends to be the person who did the work with the young person, and so they have a slew of extra context available to them about how that young person acts and how they might have changed over time. In skilled evaluation, this link is broken. Skilled evaluators tend towards becoming a kind of bureaucrat; their job is to receive, construct and disseminate information, or to control the flow of information or data. As such, they are highly powerful actors in what has become an incredibly information-dependent system.

We can think of our skilled evaluators as a kind of professional class of workers. They have invented the profession of Evaluator (although their actual role will likely be something more like 'Research Officer'). It is their job to know the latest trends in evaluation practice, the tools everyone is using, the right way to set up an evaluation scheme, to put on their outcomes head at a moment's notice. [academic work on dangers of professionalisation?] The danger of having created a professional class of evaluators, however, is that they then become a sort of snake-oil salesman, able to turn any piece of data they receive into a compelling argument for an evaluation report. Instead of creating very subjective data, the danger of the skilled evaluator is in creating data that seems too clean. They are able to subjectively pick from existing data, or ask the right questions that will give them the answers they (or funders, or policymakers) want to hear.

There is also the possibility that they will be working with the data of other services, at a meta-level. One of the evaluators I worked with, [Sohila] complained to me that she hated dealing with other services' data because of the inconsistency between them:
What am I supposed to do with that? The data produced by different services isn't uniform, it's inconsistent on how they've collected data for different metrics, they've picked and chosen different outcomes from god-knows-where and they may or may not have run their own evaluation, probably in a completely different way than we would have suggested they do it. There's no sense in it whatsoever.
These services sound like they have conducted evaluation in an unskilled way. Yet it is [Sohila]'s job to do something with this. Having oversight of lots of different projects means that professional evaluators can draw from multiple sources when trying to attest to the brilliance of the work their organisation does. Can't find the data in Leicester? You might find it in Somerset, instead. Having such a vast range of sources means that professioanl evaluators are always able to construct a more convincing evaluation than a smaller charity or unskilled evaluator could. It is not just the implicit knowledges that professional evaluators have access to, or the networks and relationships they may maintain with policy organisations that makes them produce better evaluations: it is also the fact that they have a disproportionately large source of data, and the capacity and funding to do something with it. As [Sohila explained to me at the end of this conversation:

We have no reason to think we do anything better than anyone else. The data isn't there to support it. But we have to pretend we do, otherwise we'd never get funded.

The lack of context and bureaucratisation that is made manifest in the professional evaluator furthers the disconnect between the material reality of frontline practice and the onward legacy of that practice. A worker might have a genuinely transformative relationship with a young person, where the young person knows they can rely on the worker and can open up about anything to them. Yet it is only the inscriptions this worker makes of their relationship that have an onward path. Suppose they choose not to fill in a feedback form during a session because they are trying to listen to the young person in a genuine, authentic and meaningful way. Because of this, they wait until they are back in the office to write their notes from the session. In that time, they have already forgotten so much about what happened. Their workload allocation model doesn't actually take into account the fact they have to feedback on every session, and they're managing a caseload of 25 to 30 young people, who they have a statutory responsibility to see once a month - so that's more than one a day. The worker scribbles down some hurried notes and goes to their next session. Those hurried notes are the only traces made of their interactions with the young person - and they are all the professional evaluator has to work with. Good practice may instead just end up looking like average or even subpar work. The evaluator cannot ask more about what happened to fill in the gaps, so the great work this worker does can't be used to form part of the evaluation, or any level of organisational policy proposal. The faintest traces cannot become indelible.

The opposite of this is also true - bad practice can actually appear to be good practice. This gap between what is and what appears to be speaks to a gap between discourse and reality. At the discursive level, a project or organisation may appear to be doing very genuinely good things, using all of the latest buzzwords, claiming to have a deeply participatory approach and supporting young people through some of the hardest times in their lives. Yet in reality, this may not ever happen - a skilled evaluator may have been able to spin the limited input of three young people (always the same three young people, perhaps) into genuine co-production. For example, Building Bridges describes the program they run as co-produced, and that they "embed the voice of young people in all that we do". This was an aim for the project before it began and continues to be a basis on which it is evaluated. In the evaluation report of the first year of the program, [Sohila] noted that Building Bridges "made experts and workers feel like [parent org] was really interested in hearing from them". Whilst this was true at some levels, participation and co-production were deliberately curtailed at some stages. For example, throughout the program, [Richard] had a tendency to appear to open a discussion on what young people would like to happen. In reality, he always had a desired endpoint; he would keep discussion going until the group had reached the answer he wanted, or would he would make some reason that things had to be the way that he suggested. These were not huge moments, but these were consistent ways that the fidelity of co-production and participation were undermined throughout the program. Yet of course, the evaluation spends a great deal of time explaining the positives in Building Bridges' approach, and makes no reference to moments such as this, except with the ambiguous reminder that "Proving that the team is listening to feedback from participants is crucial".

\section{Justification practices}
After years of financialisation and marketisation, and operating in an environment of precarity and contingent funding, 'evidence-based' policy and decision-making, and 'value for money' as the central measure of success of an organisation engaged in service delivery, charities have changed. The changes weren't quick, and weren't wholly brought on by austerity; but slowly, over time, youth and social work practice has changed. The measurement of outcomes and creation of outputs has become the order of the day. The labour of evaluation hangs over the delivery of all frontline practice. If you can't justify why you want to do your project in terms of outcomes and outputs, or if you can't justify how your project has made the change that it has, your project may as well not exist. I refer to the solidification of this existence into everyday youth and social work practice as 'justification practices'. Justification practices describe the prioritisation of this kind of working above all else; a change in the raison d'etre of youth and social work. The bottom line is no longer assessment of needs for support (as it was in the days of the Charitable Organisation Society, the birth of one strand of modern social work), nor the critical education of oppressed people (as in the Marxist conception of social work), but the delivery of certain pre-determined outcomes for a client (the state). In short, social work has been subsumed by the neoliberal New Public Management model of operating. Termed differently, we could consider this kind of work as the delivery of changes to key performance indicators for service users. maybe one more sentence on KPIs and other neoliberal NPM technologies

Justification practices refer to the work needed to stabilise this change in social reality. They are a dynamic set of practices, though they may often make use of static things to make their arguments. They seek to constantly transform in order to remain relevant to the constantly-shifting-target that is the state and attitudes of funders. Above everything, charities and services engaged in this work want to continue existing. We cannot chastise them for this: as we have seen, charity workers start out with 'good intentions', and they believe it to be preferable that they are able to deliver some kind of intervention than nothing. After all, if it wasn't for them then maybe no one would support the young people they work with? Right? Because the need to continue existing guides everything, justification practices emerge in the gap that the eroding good intentions leave. We see justification practices when an organisation applies for and receives funding for something they "wouldn't normally do", but needed the funding to keep them afloat. We see justification practices when a worker is less interested in listening to a young person and more interested in making their pathway plan. We see justification practices when an evaluation report changes a failed program into something that "needs more work, but shows promising beginnings". Justification practices are not limited to charities; even in local authorities, when they run in-house social service operations, they begin enacting justification practices. Their funder is the government, and they use justification practices to stabilise their relationship with the state, maintaining the appearance of value for money at whatever cost, even if they are struggling.

In the previous chapter, I outlined a set of experiences which characterise living and working in the care system: managers couldn't trust their workers, and felt their good intentions slipping as they began enacting techniques of control. Workers cannot trust their managers, and so act in a deferential and dishonest way, needing to seem constantly whilst having too much work to do until they become anxious, paranoid, burnt out and begin enacting their own techniques of control with young people. Young people feel as if they aren't listened to or taken seriously, and can't get the support that they need, and so they begin to feel powerless, unable to imagine the possibility of change and finding it difficult to enter into relationships of trust. They feel isolated, abandoned and unworthy of support, whilst feeling anxious and disoriented at all of the different directions the system ends them in. All of these experiences are underpinned and punctuated by justification practices. The manager who begins acting in a controlling way with their staff is doing so because they are terrified the staff will do something wrong which prevents the charity from accessing funding and therefore existing. The worker who feels burnt out but is aware of the need to seem constantly busy is terrified of losing their job if they seem under-productive. Young people feel anxious and disoriented because when they try to access support, they're thrown around different bureaucratic systems filled with workers who don't understand their needs and who thinks about them only in terms of outcomes.Negative affects saturate the care system, and are brought about by bad experiences which in turn are brought about by justification practices.

We can draw a direct line from the control techniques used by managers and the negative experiences that lead to negative affect and poor self-concept in care-experienced young people. This is not to suggest that managers of charities are responsible for the trauma that care-experienced young people experience; there was a reason that the state decided that this young person was no longer safe with their family. However, this is a clear example of young people being unable to access the support that they actually need. Far from helping or healing young people, services often end up entrenching the harm that is done. In his new role as a personal advisor for a local authority, Colin caught up with me and explained that he wasn't happy with some aspects of it:

"They keep saying that I'm spending too much time with him [a young person Colin was working with who had a significant disability]. But I have no time to do any of the proactive stuff. Like, I know he's going to have problems with his new hob so I could just get onto that, but I can't because I'm being told it's too much. So instead of any actual support instead we just give them money. What's the point in that? It's just teaching them to be materialistic. And then we get mad at them and say they're criminals for stealing things from shops - but we're teaching them that money's the only they can get support. It's not on."

The path towards justification practices is relatively simple. Reduce the funding of a service which affects people's lives, and make it contingent, conditional or dependent on some other thing. Make that other thing a constantly-shifting target, never attainable but always present. Insist that organisations show how they are meeting that constantly-shifting target, and insist they do so in a way that uses as little money as possible. Make their funding dependent upon their satisfactory (or exemplary) demonstration of this. Mandate that evidence or 'data' underpins the claims made, but don't dig too deep. Change the target again, making it so that their funding is dependent on not just their current demonstration of value for money but a future demonstration of value for money. Make them prove they can do whatever you want them to do, forever. Reward 'innovation'. Prioritize a culture of 'risk-takers', 'trailblazers', 'influencers', 'thought-leaders' and 'novelty'. If it's been done before, why would you care? Make the organizations show their practice is generalizable, so anyone can do it. In the gaps that all of these changes leave, justification practices arise to stabilize the social reality. Don't worry, we're still doing social work. We're still keeping to our core purpose. We care about people. We care. Honest.

Though it is not within the remit of my own work, I would be remiss to not highlight the ways in which the pattern that is present in justification practices has also taken hold in other areas of social provision affected by austerity or austerity politics. The clearest examples are that of academisation in the school system and marketisation in Higher Education. In both of these systems, organisations with an ostensibly social function are rendered subject to funding that is contingent upon 'outcomes', with outputs and accreditations guiding their functioning. Consider how academy trusts spend huge sums of money on branding - to get their 'look and feel' right, like our friends at Changemakers. Consider how universities have for years had to engage in the Research Excellence Framework, submitting their work for external approval to verify its impact, and how in research years the Teaching Excellence Framework and Knowledge Excellence Framework have guided university decision-making and their ability to set fees at the highest level. This is much like how organisations who provide services to young people have had to engage in external review - for their funders, for decisionmakers, or at national events such as Benchmarking Forums. Burrows noted the hugely damaging impact of the prioritisation of h-indices as far back as 2012 (citation), and the contemporary academy is marked by impact case studies, 'innovative' partnerships and student teaching surveys governing promotion decisions. We have begun to see the impact of this upon the National Health Service, with maximimum appointment times in GP's surgeries and the metricisation of a practice's outcomes. So too have we seen it in policing (though not a social service), with a time of reduced provision coinciding with an increase in criminalising activity and the introduction of arrest quotas; and with border 'control' agents, one of the most carceral of systems, who are assessed on their ability to deal with (manufactured) threat.

Justification practices are stabilising forces, attempts to stay afloat in an increasingly precarious world. They are an attempt to stay afloat by generating things which are static and appear empirical or universal. Yet the production of these static traces coincides with another cultural trend: the move towards datafication. The organisations engaged in justification practices necessarily engage in datafication as a means of survival, yet there is little consideration for the security, privacy or onward trajectory of the data they create. Why does that funder want you to create a database of clients with a tracker of their outcomes over time? Why do they want you to document your engagement methods as if you were writing a long and detailed recipe? Whether intentional or not, justification practices and their associated datafication facilitate a move towards the introduction of digital technologies into the youth and social work space; particularly, the introduction of automated technologies. In some cases these are automated or autonomous decision-making technologies, whilst in others they are machine learning or 'artificially intelligent' systems. What is true in all cases is that outcomes, however crudely recorded, are, in aggregate, being used to teach automated technologies what the care system and other spaces perceived to be 'vulnerable' look like, and how different kinds of practice intervenes in this. Yet justification practices just describe the stabilization work which make all of this possible. What is happening behind the scenes? Who is the 'man behind the curtain'? How do they work? What do they want? What is driving the changes that led to the creation of the Framework for Young People's Outcomes in the first place?

\section{Classification practices}
Operating at a layer above justification practices are processes of categorization and classification. We can think about the focus on outcomes as a kind of atomisation - an attempt to break down what social work does to its constituent components. We could then think about the use of evidence-based policymaking practices as a kind of explanatory function - an attempt to understand how these atoms move when subject to different forces. This is an onto-epistemological understanding of what is happening within youth and social work; first we must seek to know what exists, then we must identify how we know what the things that exist do. Classification and categorization practices are instantiated at a layer higher than justification practices to begin this program of atomisation. They seek to separate out groups of people, and classify them as functioning differently. There is a general aspect to this - in that we can think of 'normal' people and people perceived to be 'vulnerable' by the state. Yet we can also think of this vulnerability as being composed of subcategories. For example, we may entertain a separation based on age (such as youth social care and later life social are), a separation based on need (such as drug and alcohol support or mental health support), or a separation based on a set of experiences a person has (such as in the case of care-experienced young people or young people with experience of homelessness).
In Bowker and Starr's Sorting Things Out, they describe...

\subsection{Identity-based categorization}
In my work I have primarily seen the XXXXX of classification be used in an experiential sense, which we might also think of as an identity-based categorization. For example, a service may be funded to work with 'care-experienced young people', 'young people with experience of homelesness' or 'young people with experience of the criminal justice system'. The funding may explicitly state that a service is to engage a certain number of people of one of these 'types' and that they will be evaluated on the basis of this engagement. In reality, however, these people may be one and the same. There are significant intersections and pathways between care-experience, homelessness and experience of the criminal justice system (cite). In part, this is because care-experienced young people are likely to experience frequent interruptions in support which leave them without somewhere stable to live, and also because of early criminalisation, as disputes or arguments in care settings lead to the police being called rather than a de-escalation of the conflict. Yet funding dictates how and who a service may work with. This leads to a necessary identity-based classification politics within youth social service provision - rather than being able to see a young person as having diverse and varied experiences and needs, instead services have to support people on the basis of one facet of their identity.

These classification practices have material and lived effects and affects on the lives of young people attempting to access support. On the one hand, this may result in a service having to twist the truth, as [Laura] had to when working with care-experienced young people on a project to help them bypass barriers to work. She explained to me that she would be talking to a young person:

"about, you know, anxiety or depression or whatever it is. And then I have to write that down in a way that it's a barrier to work or, you know, so I'd have to just put a certain spin on it. They might not have mentioned work - they might not even be thinking about that, or college. But I have to explain to them that, you know, I'm just going to write down that this is something you're experiencing, and it's possibly a reason why you're not able to hold down a job or access college."

Although it is true that people may be unable to access or maintain work because of their anxiety or depression, in this case [Laura] was focused on finding ways that the funds her role was supported by could help her to do the work that she needed to. The way that she flexibly reconfigured the young person's problems to be framed in terms of how they access or maintain work or educational opportunities is a product of the classifications at the heart of the funding scheme. This is of course, another way that the contingency of evaluation is exploited, but it is primarily an example of how strict criteria force people to operate in a certain way.

The other side of the tightness of these classifications is the use of deficit-led framings or stigmatising language. If a funding scheme is established in a way that those with lived experience of the problems that it discusses believes to be stigmatising, there will be significant harm incurred to those who are a part of the project. Yet as we have seen, punitive funding regimes can make workers who may well know better than to use this stigmatising language begin to use it in their practice, for fear of eventually losing funding. It may not be the worker themself that has this fear; it may be their manager, who enacts and lives this fear through one or several control techniques. It may just be a product of the environment that they work in. Nonetheless, the impact is the same; young people can be made to feel that they are at fault for their material circumstances because of the language or framing that is used in a project they are a part of.

For example, when working with Firhampton County Council on a filmmaking project about life story work (detailed further in chapter 6), the senior social workers all explained how they thought imagery in the film might look with deficit framings. The project was supposed to be about how life story work can be of benefit to care-experienced young people, and was meant to be an honest reflection of young people's experiences of life story work. The senior social workers suggested imagery to be used in the film of a person being gradually built up with LEGO, or drawings of "half a person" being reunited with their other half through the use of life story work. Whilst the workers had intended the point here to be about how life story work can be therapeutic through the restoration of lost knowledge, the visuals they were advocating all suggested that care-experienced young people would be incomplete or less than if they didn't receive life story work - which was most of the young people in Firhampton at the time, hence the film being commissioned. This can also affect who becomes involved with a project. Repeatedly throughout Building Bridges - both in its first year and before it began - Michael referred to the kind of young people that he wanted to work with on the program as "rough and raw", or the "tricky customers", rather than working with young people who are always a part of participation initiative. Whilst Michael's intention here was good - he wanted to avoid tokenism - by conceptualising these young people as rough, raw and tricky, he promotes the idea that they are in somehow less than, unable to keep up with the trappings of liberal bourgeois society. In some ways, he evokes the classical image of social work; of helping "ragged children" as Dr Thomas Barnardo did when he began kidnapping poor children in the late 1800s.

These strict and tight classifications of who can be the focus of a planned project or intervention also leads to the stratification or specialisation of knowledge and practice. One day in a Small Steps team meeting, we were joined someone from another charity who had received some funding to do a project with care-experienced young people. They explained their idea and was hoping to be able to work with Small Steps to run the program. When a member of the team questioned the guest on an aspect of what they wanted to do, they were completely clueless:

"Oh, well, I don't know about engaging care leavers... that's not something we really do. You guys know much more about that, so I think we'd be looking to you on that one."

After she left, the team were understandably incredulous that the guest couldn't answer their fairly basic question. Yet it was not necessarily her fault; in a lot of ways, the woman from the guest organization was just 'doing her job'. The funding system that is currently in place makes out that work with different groups of people is necessarily significantly specialised. Whilst there may be some additional considerations when working with a care-experienced young person to working with someone without care experience, this is not and should not be the defining feature of the practice. The current funding regime instead makes out that all areas of work are highly specialised, and if you are intending to engage a group of people outside of your core expertise then there are specific methods and paradigms you should be following to work in this way. After the directors of Changemakers and Small Steps spoke with each other in a meeting I organised, [Sharon] said to me that she appreciated [Mari]'s views but that "things are so much easier for her because she's trying to engage care-experienced young people", as in [Sharon]'s eyes young people with experience of homelessness were much harder to engage. This neglects to take account of the fact that care-experienced young people are at significant risk of experiencing homelessness, and at the time the majority of people the organisation was working with had experience of the care system.

The logical endpoint of this kind of identity-based categorisation is a system in which people are viewed in a financialized way. As I mentioned, Michael referred often to the idea of the young people he wanted to work with as "tricky customers". He also referred to the work of Building Bridges as a program of "investing in young people", whilst [Sohila] referred to the activities undertaken by [parent charity] as "products". This is a fairly transparent way of conceptualising the work of service providers: they deliver products to customers, and invest in those customers. Whilst the metaphor is somewhat confused, it is clear that care-experienced young people here are being thought about in solely financial terms. Service provision is framed in terms of specific monetary investment delivered to specific individuals. This even goes down the level of financial management and accounting - workers will have to cost expenditure to specific projects for the sake of effective accountancy and program evaluation. Yet if you are working with a young person on multiple projects, how do you decide which money is for which? Ultimately a decision has to be made about how the work is being paid for. This process further entrenches the contingency and inauthenticity of evaluation processes, but also solidifies the bottom line of everything: all activities have to be costed to one project or another.

\subsection{Forced engagement}
Identity-based categorization that is led by funding for specific groups can also lead to a sort of forced engagement. In the case of forced engagement, the tension between the needs of the charity at an organizational level and the needs of young people at a material level are in discordance. Charity's needs are always to exist whilst doing - or appearing to do - as much good as they can. Yet what happens if a charity gets funded to deliver a program nobody wants, or that there isn't a need for? This is where forced engagement comes in....

YP and charities have different needs - charities need to continue existing. Strict funding criteria can prevent organisations responding to demonstrable needs. When funding is received, organizations don't have great links with young people so they often resort to either tokenistic participation, revisiting the same young people over and over, or they seek to engage young people on their own terms - either responding to the charity's needs or because they have been told to. The trend of co-production means that even where there is demonstrable need but no group to co-produce, young people are forced to engage or the need is not met.
Young people and charities have different needs. Engagement that is led by charities responds more to their own needs than to that of young people. This can result in forced engagement or tokenistic participation.

\subsection{The appearance of co-production // control practices}
Organizations claim to co-produce their work with young people. They claim to believe in the value of young people having a 'voice'. It is important to note this is just a 'voice' and not any meaningful actions or use of their power. Just because they claim to co-produce, this doesn ot mean that they do.

Because the needs of organizations and young people are different (FE), organizations feel a need to control the outcomes of a project whilst appearing to co-produce. This can include influencing behaviour change and limiting the actual range of options and choices young people can take, or giving them more power over less influential decisions.

When organizations cannot control the content of co-production, they experience a series of negative affects (anxiety, pessimism, annoyance). There is a view that giving up this power will lead to things going bad, and so this makes them more risk averse - strengthening their power, loosening the ability of YP to make meaningful decisions. This may include engaging in tokenistic participation, preventing young people from talking to each other properly, trying to guide, steer or control what young people do.
These practices may also extend from the manager to their workers - workers may exhibit these same behaviours because their managers encourage them to, or managers may refuse to listen to their workers or engage in co-production with them.

Digital technologies can facilitate a paranoid organization's want for control as many digital technologies - particularly for vulnerable young people - include carceral functions that limit the possibilities of young people to act, reflect, disclose or connect. Digital spaces are seen as 'more dangerous' and so the need to restrict, 'protect' and control is intensified.
These control techniques become increasingly sophisticated, and can enlist the help of sophisticated (or rudimentary) technologies as a way to support them.

% wacjman on time
% •	sophiticated tech
% •	visual: 
% o	dataviz
% o	box-ticking
% o	gantt charts/visuals of time
% o	quotes
% o	infopacks
% o	'tracking'

\section{Performativity! in the knowledge ecosystem}
/

% The construction of 'best practice'
% Innovation
% De-innovation
% Technologization
% Discussion
% •	Creation of ‘vulnerable’ environment
% •	Anticipatory practices/ future(justification practices): change in orientation towards probable futures changes practices in the present
% •	Technologies and techniques of control, what they are and their impacts – and lack of trust
% •	Extractive listening and practices
% •	Impacts of performativity
% •	Classification (quantification, measurement, standardization)
% •	Datafication
% o	automated systems (AI ML ADM) and implications of JPs etc on them
% •	classification and quantification —> change in anticipatory practices —> performativity, lack of trust —> control behaviours —> extraction —> negative affects
% •	stabilisation of a particular kind of knowledge regime; (looping effects, biopolitics, governmentality which intensify this, and how digital tech ties into it
% •	restriction of possibility: change in self-experience and ‘slow cancellation of the future’ etc
% o	negative self-talk which damages self-concept
% •	exponential looping effects on a systems level
% •	horrible dynamics between workers and managers and young people
% •	'hackability' of the care system
% •	how this applies to other systems with similar dynamics: NHS, prisons, education, HE
% •	How do we design against these?
% By classifying young people as vulnerable, the type of engagement that can be done with them is limited and reflects the needs of organizations and funders moreso than YP. This results in the organization controlling more and more and becoming more anxious about a lack of control - but other data shows that 'not being in control'/being vulnerable may be key to recovering from some of these problems... Carceral technologies facilitate this, strengthening the ability of organizations to restrict possibilities, imaginaries and actions. The datafication required for the move towards these carceral technologies seeks to classify again; and seeks to move towards ADM systems to restrict the possible negative things that can happen to actors classified as vulnerable.
% Having seen the effects and affects of this new culture of evaluation on youth charities, I shall refer hereafter to evaluation as a technology, with affordances, disaffordances, intended users and functions. Just like any technology, however, evaluation processes are open to user appropriation, and I argue that the intensification of evaluation processes as a result of austerity led to a resurgence in methods of appropriation of them, which I refer to as justification practices.
% Conclusion
% In this and the preceding chapter, I have explored the experiences that underpin living in the care system since the advent of austerity.
% •	datafication 
% o	ramifications of classification and performativity on AI, ML, alg gov/ADM
% •	performativity 
% o	fake news, social media/identity management?
% •	control behaviours 
% o	slow cancellation of the future 
% 	no change, no possibility of change, disorientation, on their own
% 	a need to re-engineer the possibility of other, plural futures.



